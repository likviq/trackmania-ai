{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "CSV_PATH = \"E:\\\\study\\\\bachelor\\\\temp-files\\\\data\\\\Obtain data\\\\dataframes\\\\2023_summer_01.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        img_path = self.dataframe.iloc[idx]['image_path']\n",
    "        speed = self.dataframe.iloc[idx]['speed:']\n",
    "        cur_gear = self.dataframe.iloc[idx]['curGear:']\n",
    "        side_speed = self.dataframe.iloc[idx]['sideSpeed:']\n",
    "        input_value = self.dataframe.iloc[idx]['inputSteer:']\n",
    "        \n",
    "        image = Image.open(img_path)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, speed, cur_gear, side_speed, input_value\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize((224, 224)),\n",
    "                                transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, shuffle=False)\n",
    "\n",
    "train_dataset = CustomDataset(dataframe=train_df, transform=transform)\n",
    "test_dataset = CustomDataset(dataframe=test_df, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([414.3712, 418.2422, 418.2422, 421.8478, 426.6600, 426.6600, 430.7733,\n",
      "        430.7733, 435.1370, 439.4427, 439.4427, 443.8688, 443.8688, 441.9210,\n",
      "        441.9210, 438.6070, 438.6070, 430.6454, 430.6454, 420.8506, 420.8506,\n",
      "        422.3002, 422.3002, 426.7839, 426.7839, 430.6572, 430.6572, 434.2073,\n",
      "        434.2073, 439.2469, 439.2469, 450.2664], dtype=torch.float64)\n",
      "tensor([450.2664, 450.1349, 449.1153, 449.1153, 449.2356, 449.2356, 450.1953,\n",
      "        450.1953, 452.5691, 456.0013, 456.0013, 460.8422, 460.8422, 466.6814,\n",
      "        466.6814, 469.0249, 469.0249, 468.5157, 468.5157, 467.0493, 467.0493,\n",
      "        466.3409, 465.8801, 465.8801, 465.2509, 465.2509, 463.7188, 463.7188,\n",
      "        462.2636, 462.2636, 462.0839, 462.0839], dtype=torch.float64)\n",
      "tensor([462.8607, 462.8607, 464.9398, 464.9398, 470.5648, 470.5648, 476.4546,\n",
      "        476.4546, 549.6478, 549.6478, 635.3073, 635.3073, 652.0865, 648.6982,\n",
      "        648.6982, 646.0998, 644.0226, 644.0226, 637.4882, 628.0352, 628.0352,\n",
      "        622.2201, 622.2201, 618.3866, 618.3866, 618.4925, 618.4925, 624.8641,\n",
      "        624.8641, 630.7678, 630.7678,   0.8105], dtype=torch.float64)\n",
      "tensor([  0.8105,  11.5620,  11.5620,  23.2688,  35.3945,  35.3945,  47.3822,\n",
      "         47.3822,  59.5019,  59.5019,  71.6998,  71.6998,  82.0631,  95.6818,\n",
      "         95.6818, 101.8024, 101.8024, 102.4708, 102.4708, 110.4576, 110.4576,\n",
      "        118.4775, 118.4775, 126.4768, 126.4768, 134.4568, 134.4568, 142.6600,\n",
      "        142.6600, 150.7030, 150.7030, 158.4486], dtype=torch.float64)\n",
      "tensor([158.4486, 161.8924, 161.8924, 166.9297, 166.9297, 174.8259, 174.8259,\n",
      "        182.7503, 182.7503, 188.5206, 188.5206, 192.0699, 192.0699, 194.0710,\n",
      "        194.0710, 195.6863, 195.6863, 198.6080, 198.6080, 202.9114, 202.9114,\n",
      "        207.8131, 207.8131, 213.1202, 213.1202, 218.4016, 218.4016, 223.8671,\n",
      "        229.7833, 229.7833, 235.1618, 235.1618], dtype=torch.float64)\n",
      "tensor([236.5447, 236.5447, 242.3294, 242.3294, 248.1464, 248.1464, 253.7441,\n",
      "        253.7441, 259.4543, 259.4543, 265.0311, 265.0311, 270.4084, 270.4084,\n",
      "        275.0750, 275.0750, 279.3292, 279.3292, 293.5421, 293.5421, 319.7401,\n",
      "        319.7401, 346.2184, 346.2184, 372.7268, 372.7268, 378.7553, 378.7553,\n",
      "        383.3163, 387.3848, 387.3848, 386.6523], dtype=torch.float64)\n",
      "tensor([386.6523, 385.9099, 385.9099, 390.2500, 390.2500, 394.4028, 394.4028,\n",
      "        398.4597, 398.4597, 402.1573, 402.1573, 405.9153, 405.9153, 409.8645,\n",
      "        409.8645, 413.9977, 413.9977, 417.6924, 417.6924, 421.7258, 421.7258,\n",
      "        426.1897, 430.2748, 430.2748, 434.6203, 434.6203, 438.5359, 438.5359,\n",
      "        443.1377, 443.1377, 442.7674, 442.7674], dtype=torch.float64)\n",
      "tensor([439.1907, 434.4576, 434.4576, 421.5748, 421.5748, 421.1880, 421.1880,\n",
      "        426.0575, 426.0575, 430.0375, 430.0375, 433.7035, 433.7035, 437.5982,\n",
      "        437.5982, 448.8040, 448.8040, 450.3605, 450.3605, 449.3804, 449.3804,\n",
      "        448.9456, 448.9456, 449.8589, 449.8589, 451.8370, 451.8370, 455.1479,\n",
      "        455.1479, 459.7561, 459.7561, 465.6488], dtype=torch.float64)\n",
      "tensor([465.6488, 468.6709, 468.6396, 468.6396, 467.5450, 467.5450, 466.5147,\n",
      "        466.5147, 465.8511, 465.7936, 464.0428, 464.0428, 462.6182, 462.6182,\n",
      "        462.1093, 462.1093, 462.5659, 462.5659, 464.5208, 464.5208, 469.4314,\n",
      "        469.4314, 475.1613, 475.1613, 531.1566, 531.1566, 615.3318, 615.3318,\n",
      "        653.3377, 653.3377, 649.9750, 649.9750], dtype=torch.float64)\n",
      "tensor([646.7332, 646.7332, 644.6284, 644.6284, 639.8136, 639.8136, 627.9974,\n",
      "        622.9057, 622.9057, 619.1566, 619.1566, 616.9537, 622.8378, 622.8378,\n",
      "        629.1781, 629.1781, 622.7949, 622.7949,   7.5632,   7.5632,  19.6364,\n",
      "         19.6364,  31.4109,  31.4109,  43.2468,  43.2468,  54.8674,  54.8674,\n",
      "         66.3864,  66.3864,  78.5898,  78.5898], dtype=torch.float64)\n",
      "tensor([ 90.3813,  90.3813, 101.8884, 101.8884, 101.7845], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "for batch in test_loader:\n",
    "    image, speed, cur_gear, side_speed, input_value = batch\n",
    "    print(speed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
